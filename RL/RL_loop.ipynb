{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gymnasium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gymnasium'"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "import wandb\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTwoBus:\n",
    " \n",
    "    def __init__(self, V_ext, P, Q, G, B, V_init, theta_init, V_bus1, theta_bus1):\n",
    "        '''This class creates a simple 2-bus network.'''\n",
    "        \n",
    "        self.V_ext = V_ext\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.V_init = V_init\n",
    "        self.theta_init = theta_init\n",
    "        self.V_bus1 = V_bus1\n",
    "        self.theta_bus1 = theta_bus1\n",
    "        self.net = pp.create_empty_network()\n",
    "        self.create_two_bus_grid()\n",
    " \n",
    " \n",
    "    def create_two_bus_grid(self):\n",
    "   \n",
    "        # Create two buses with initialized voltage and angle\n",
    "        bus1 = pp.create_bus(self.net, vn_kv=1.0, name=\"Bus 1\")\n",
    "        bus2 = pp.create_bus(self.net, vn_kv=1.0, name=\"Bus 2\")\n",
    "   \n",
    "        # Initialize voltage and angle for buses\n",
    "        self.net.bus.loc[bus1, 'vm_pu'] = self.V_bus1\n",
    "        self.net.bus.loc[bus1, 'va_degree'] = self.theta_bus1\n",
    "        self.net.bus.loc[bus2, 'vm_pu'] = self.V_init\n",
    "        self.net.bus.loc[bus2, 'va_degree'] = self.theta_init\n",
    "   \n",
    "        # create a line between the two buses\n",
    "        pp.create_line_from_parameters(\n",
    "            self.net,\n",
    "            from_bus=0,\n",
    "            to_bus=1,\n",
    "            length_km=1.0,\n",
    "            r_ohm_per_km=1/self.G,\n",
    "            x_ohm_per_km=1/self.B,\n",
    "            c_nf_per_km=0.0,\n",
    "            g_us_per_km=0.0,\n",
    "            max_i_ka=100.0,\n",
    "        )\n",
    " \n",
    "        # Create a transformer between the two buses\n",
    "        # pp.create_transformer(self.net, bus1, bus2, std_type=\"0.25 MVA 20/0.4 kV\")\n",
    "   \n",
    "        # Create a load at bus 2 with specified P and Q\n",
    "        pp.create_load(self.net, bus2, p_mw=self.P, q_mvar=self.Q, name=\"Load\")\n",
    "   \n",
    "        # Create an external grid connection at bus 1 with specified G and B\n",
    "        pp.create_ext_grid(self.net, bus1, vm_pu=self.V_ext, name=\"Grid Connection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv(gym.Env):\n",
    "    def __init__(self,V_ext = 1.0, G = 100, B = 10, k_limit = 5, max_iteration=50, termination_counter=10):\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Box(low = np.array([0.5,-90, 0]), high = np.array([2, 90, max_iteration+1]), dtype=np.float32) #[V_init, theta_init, number_iterations]\n",
    "        \n",
    "        self.action_space = spaces.Box(low=np.array([-0.5, -50]), high=np.array([0.5, 50]), dtype=np.float32)\n",
    "\n",
    "        self.k_limit = k_limit\n",
    "        self.termination_counter = termination_counter\n",
    "        self.max_iteration = max_iteration\n",
    "\n",
    "\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.V_ext = V_ext\n",
    "\n",
    "        #initialize network\n",
    "        self.state, info = self.reset()\n",
    "\n",
    "    def create_feasible_Ybusnet(self):\n",
    "\n",
    "        YbusNet = SimpleTwoBus(self.V_ext,self.P,self.Q,self.G,self.B,self.V_bus1,self.theta_bus1, 0.98, 0.5) #just to create a sparse Ybus matrix\n",
    "        net = YbusNet.net\n",
    "\n",
    "        return net\n",
    "\n",
    "\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            self.seed(seed)\n",
    "\n",
    "        self.counter = 0\n",
    "        self.done = False\n",
    "        self.terminated = False\n",
    "        self.state = np.zeros(3)\n",
    "\n",
    "        self.P = 0.9 #np.random.uniform(low= 0, high=10)\n",
    "        self.Q = 0.6 #np.random.uniform(low = 0, high =10)\n",
    "\n",
    "        self.V_bus1 = 1.0#np.random.uniform(low = 0.85, high = 1.15, size=1)\n",
    "        self.theta_bus1 = 0#np.random.uniform(low = -45, high = 45, size=1)\n",
    "        self.V = np.random.uniform(low = 0.5, high = 2, size=1) # initial guess\n",
    "        self.theta = np.random.uniform(low = -90, high = 90, size=1) # initial guess\n",
    "\n",
    "\n",
    "        Net = SimpleTwoBus(self.V_ext,self.P,self.Q,self.G,self.B,self.V,self.theta, self.V_bus1, self.theta_bus1)\n",
    "        self.net = Net.net\n",
    "\n",
    "        self.Ybus = self.calculate_Ybus()\n",
    "\n",
    "        iterations = self.perform_NR_step()\n",
    "\n",
    "        \n",
    "        self.update_state(iterations)\n",
    "\n",
    "\n",
    "        return self.state, {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_Ybus(self):\n",
    "\n",
    "\n",
    "        Ybusnet = self.create_feasible_Ybusnet()\n",
    "        pp.runpp(Ybusnet, max_iteration = self.max_iteration, tolerance_mva=1e-5)\n",
    "        Ybus = Ybusnet._ppc[\"internal\"][\"Ybus\"]\n",
    "\n",
    "\n",
    "\n",
    "        return Ybus\n",
    "\n",
    "\n",
    "    def calculate_complex_V(self, V, theta):\n",
    "        complex_V = V*np.exp(1j*theta) #rectangular form\n",
    "\n",
    "        return complex_V\n",
    "    \n",
    "    def update_V(self, action):\n",
    "\n",
    "\n",
    "        new_V = self.V - action[0]\n",
    "        new_theta = self.theta - action[1]\n",
    "\n",
    "\n",
    "        # maybe try different way of scaling the actions back when they exceed the limits?\n",
    "        #defines the action constraints -> this might not be the correct way to do this!\n",
    "        if new_V > 2:\n",
    "            new_V = 2 \n",
    "        if new_V < 0.5:\n",
    "            new_V = 0.5\n",
    "        if new_theta > 90:\n",
    "            new_theta = 90\n",
    "        if new_theta < -90:\n",
    "            new_theta = -90\n",
    "        \n",
    "\n",
    "\n",
    "        complete_V = np.zeros(2)\n",
    "        complete_theta = np.zeros(2)\n",
    "\n",
    "        complete_V[0] = self.V_bus1\n",
    "        complete_V[1] = new_V\n",
    "        complete_theta[0] = self.theta_bus1\n",
    "        complete_theta[1] = new_theta\n",
    "\n",
    "        self.complex_V = self.calculate_complex_V(complete_V, complete_theta)\n",
    "\n",
    "\n",
    "\n",
    "        self.V = new_V\n",
    "\n",
    "        self.theta = new_theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_residual(self, action):\n",
    "\n",
    "        # net = self.net.deepcopy()  # Keep the network unchanged\n",
    "\n",
    "        self.update_V(action) #rectangular form\n",
    "        # print(f\"{self.complex_V=}\")\n",
    "\n",
    "        # print(f\"{self.Ybus[0,1]=}\")\n",
    "\n",
    "        term2 = self.Ybus@self.complex_V\n",
    "        term2_complex_conj = np.conj(term2)\n",
    "\n",
    "        term1 = self.complex_V@term2_complex_conj\n",
    "\n",
    "        F = self.P + 1j*self.Q - term1\n",
    "\n",
    "        delta_P = np.real(F)\n",
    "        delta_Q = np.imag(F)\n",
    "\n",
    "        residual = np.array([delta_P, delta_Q])\n",
    "\n",
    "\n",
    "\n",
    "        return residual\n",
    "\n",
    "\n",
    "    def perform_NR_step(self):\n",
    "\n",
    "        net = self.net.deepcopy()  # Keep the network unchanged\n",
    "\n",
    "        try:\n",
    "            pp.runpp(net, max_iteration = self.max_iteration, tolerance_mva = 1e-5, init_vm_pu=self.V,init_va_degree=self.theta)\n",
    "            # print(f\"{net.res_bus[['va_degree']].values=}\")\n",
    "            # print(f\"{net.res_bus[['vm_pu']].values=}\")\n",
    "        \n",
    "\n",
    "            iterations = net._ppc[\"iterations\"]\n",
    "        except:\n",
    "            iterations = 50\n",
    "            # print(f\"{net.res_bus[['va_degree']].values=}\")\n",
    "            # print(f\"{net.res_bus[['vm_pu']].values=}\")\n",
    "\n",
    "        return iterations\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    def calculate_reward(self, residual):\n",
    "\n",
    "\n",
    "        reward = np.linalg.norm(residual)\n",
    "\n",
    "        return -reward\n",
    "    \n",
    "\n",
    "    def update_state(self, iterations):\n",
    "        \n",
    "        self.state[0] = self.V\n",
    "        self.state[1] = self.theta\n",
    "        self.state[2] = iterations\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "\n",
    "        self.counter += 1\n",
    "        # action = [delta_V, delta_theta]\n",
    "\n",
    "        # perform action\n",
    "        residual = self.calculate_residual(action)\n",
    "        print(f\"{residual=}\")\n",
    "\n",
    "        # calcualate reward\n",
    "        reward = self.calculate_reward(residual)\n",
    "\n",
    "        iterations = self.perform_NR_step()\n",
    "\n",
    "        #update state:\n",
    "        self.update_state(iterations)\n",
    "\n",
    "        if iterations <= self.k_limit:\n",
    "            self.done = True\n",
    "            return self.state, reward, self.done, self.terminated, {}\n",
    "\n",
    "        \n",
    "\n",
    "        if self.counter == self.termination_counter:\n",
    "            self.terminated = True\n",
    "            return self.state, reward, self.done, self.terminated, {}\n",
    "\n",
    "        return self.state, reward, self.done, self.terminated, {}\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    def render(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "\n",
    "\n",
    "env = GridEnv()\n",
    "\n",
    "k_list = []\n",
    "for i in range(int(1000)):\n",
    "\n",
    "    state, info = env.reset()\n",
    "    k = state[-1]\n",
    "    k_list.append(k)\n",
    "\n",
    "\n",
    "#view the distribution of hard and easy cases\n",
    "plt.figure()\n",
    "plt.hist(k_list)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.show()\n",
    "# print(\"Initial State:\", state)\n",
    "# # env.render()\n",
    "\n",
    "# # Define a sample action within the specified ranges\n",
    "# action = np.array([0.03, 15.0], dtype=np.float32)\n",
    "\n",
    "# # Take a step in the environment using the sample action\n",
    "# next_state, reward, done, terminated, info = env.step(action)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"\\nAction Taken:\", action)\n",
    "# print(\"Next State:\", next_state)\n",
    "# # env.render()\n",
    "# print(\"Reward:\", reward)\n",
    "# print(\"Done:\", done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(WandbCallback, self).__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Check if the episode is done\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            # Log the episode return (sum of rewards)\n",
    "            episode_reward = self.locals[\"infos\"][0].get(\"episode\", {}).get(\"r\", 0)\n",
    "            episode_length = self.locals[\"infos\"][0].get(\"episode\", {}).get(\"l\", 0)\n",
    "            self.episode_rewards.append(episode_reward)\n",
    "            self.episode_lengths.append(episode_length)\n",
    "            wandb.log({\"episode_reward\": np.mean(self.episode_rewards[:-100]), \"episode_length\": np.mean(self.episode_lengths[:-100])})\n",
    "            print(f\"{episode_reward=}\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an RL agent on the environment from above\n",
    "wandb.init(project=\"grid-env-training\")\n",
    "env = GridEnv()\n",
    "lr = 1e-2\n",
    "total_timesteps = 1e6\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate = lr)\n",
    "model.learn(total_timesteps=total_timesteps, callback = WandbCallback())\n",
    "model.save(f\"saved_models2/PPO_{lr=}_{total_timesteps=}\")\n",
    "\n",
    "wandb.finish()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ictwi_alliander_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
