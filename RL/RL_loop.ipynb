{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gymnasium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gymnasium'"
     ]
    }
   ],
   "source": [
    "import pandapower as pp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTwoBus:\n",
    " \n",
    "    def __init__(self, V_ext, P, Q, G, B, V_init, theta_init):\n",
    "        '''This class creates a simple 2-bus network.'''\n",
    "        \n",
    "        self.V_ext = V_ext\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.V_init = V_init\n",
    "        self.theta_init = theta_init\n",
    "        self.net = pp.create_empty_network()\n",
    "        self.create_two_bus_grid()\n",
    " \n",
    " \n",
    "    def create_two_bus_grid(self):\n",
    "   \n",
    "        # Create two buses with initialized voltage and angle\n",
    "        bus1 = pp.create_bus(self.net, vn_kv=20.0, name=\"Bus 1\")\n",
    "        bus2 = pp.create_bus(self.net, vn_kv=0.4, name=\"Bus 2\")\n",
    "   \n",
    "        # Initialize voltage and angle for buses\n",
    "        self.net.bus.loc[bus1, 'vm_pu'] = self.V_init[0]\n",
    "        self.net.bus.loc[bus1, 'va_degree'] = self.theta_init[0]\n",
    "        self.net.bus.loc[bus2, 'vm_pu'] = self.V_init[1]\n",
    "        self.net.bus.loc[bus2, 'va_degree'] = self.theta_init[1]\n",
    "   \n",
    "        # create a line between the two buses\n",
    "        pp.create_line_from_parameters(\n",
    "            self.net,\n",
    "            from_bus=0,\n",
    "            to_bus=1,\n",
    "            length_km=1.0,\n",
    "            r_ohm_per_km=1/self.G,\n",
    "            x_ohm_per_km=1/self.B,\n",
    "            c_nf_per_km=0.0,\n",
    "            g_us_per_km=0.0,\n",
    "            max_i_ka=100.0,\n",
    "        )\n",
    " \n",
    "        # Create a transformer between the two buses\n",
    "        # pp.create_transformer(self.net, bus1, bus2, std_type=\"0.25 MVA 20/0.4 kV\")\n",
    "   \n",
    "        # Create a load at bus 2 with specified P and Q\n",
    "        pp.create_load(self.net, bus2, p_mw=self.P, q_mvar=self.Q, name=\"Load\")\n",
    "   \n",
    "        # Create an external grid connection at bus 1 with specified G and B\n",
    "        pp.create_ext_grid(self.net, bus1, vm_pu=self.V_ext, name=\"Grid Connection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv(gym.Env):\n",
    "    def __init__(self,V_ext = 1.02, G = 100, B = 0.1, k_limit = 5, termination_counter=100):\n",
    "\n",
    "        self.observation_space = spaces.Box(low = np.array([-1e10,-1e10]), high = np.array([1e10, 1e10]), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=np.array([-0.05, -30]), high=np.array([0.05, 30]), dtype=np.float32)\n",
    "\n",
    "        self.k_limit = k_limit\n",
    "        self.termination_counter = termination_counter\n",
    "\n",
    "\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.V_ext = V_ext\n",
    "\n",
    "        #initialize network\n",
    "        self.reset()\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "\n",
    "        self.counter = 0\n",
    "        self.done = False\n",
    "        self.terminated = False\n",
    "\n",
    "        self.P = np.random.uniform(low= 0, high=0.2)\n",
    "        self.Q = np.random.uniform(low = 0, high = 0.1)\n",
    "        self.V_init = np.random.uniform(low = 0.9, high = 1.1, size=2)\n",
    "        self.theta_init = np.random.uniform(low = -20, high = 20, size=2)\n",
    "\n",
    "        Net = SimpleTwoBus(self.V_ext,self.P,self.Q,self.G,self.B,self.V_init,self.theta_init)\n",
    "        self.net = Net.net\n",
    "\n",
    "        initial_guesses = np.array([self.V_init, self.theta_init])\n",
    "\n",
    "        self.state = self.calculate_residual(initial_guesses)\n",
    "\n",
    "    \n",
    " \n",
    "    # def compute_residual_torch(self, V_mag, V_ang, Ybus, S):\n",
    "    #     V_ang = torch.deg2rad(V_ang)\n",
    "    #     complex_v = V_mag*(torch.exp(V_ang*1j))\n",
    "    #     current = Ybus@complex_v\n",
    "    #     diag_V = torch.diag(complex_v)\n",
    "    #     residual = diag_V@torch.conj(current) - S\n",
    "    #     return residual \n",
    "\n",
    "\n",
    "    def calculate_residual(self, action):\n",
    "\n",
    "        net = self.net.deepcopy()  # Keep the network unchanged\n",
    "\n",
    "        pp.runpp(net, max_iteration = 1, tolerance_mva = np.inf) # not the correct function, this is just to let the environment loop be able to run\n",
    "        err = net._ppc['et']\n",
    "\n",
    "        residual = np.zeros(2)\n",
    "        residual[:] = err\n",
    "        \n",
    "        #needs a function!\n",
    "\n",
    "        return residual\n",
    "\n",
    "\n",
    "    def perform_NR_step(self):\n",
    "\n",
    "        net = self.net.deepcopy()  # Keep the network unchanged\n",
    "\n",
    "        pp.runpp(net, max_iteration = 50, tolerance_mva = 1e-5)\n",
    "\n",
    "        iterations = net._ppc[\"iterations\"]\n",
    "\n",
    "        return iterations\n",
    "        \n",
    "\n",
    "\n",
    "    def calculate_reward(self):\n",
    "\n",
    "        iterations = self.perform_NR_step()\n",
    "\n",
    "        reward = - iterations\n",
    "\n",
    "        return reward\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "\n",
    "\n",
    "        # action = [delta_V, delta_theta]\n",
    "\n",
    "        # perform action\n",
    "        residual = self.calculate_residual(action)\n",
    "\n",
    "\n",
    "        # calcualate reward\n",
    "        reward = self.calculate_reward()\n",
    "\n",
    "\n",
    "        #update state:\n",
    "        self.state = residual\n",
    "\n",
    "        if reward == -self.k_limit:\n",
    "            self.done = True\n",
    "\n",
    "        self.counter += 1\n",
    "\n",
    "        if self.counter == self.termination_counter:\n",
    "            self.terminated = True\n",
    "\n",
    "        return self.state, reward, self.done, self.terminated\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    def render(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "\n",
    "\n",
    "env = GridEnv()\n",
    "\n",
    "\n",
    "state = env.reset()\n",
    "print(\"Initial State:\")\n",
    "# env.render()\n",
    "\n",
    "# Define a sample action within the specified ranges\n",
    "action = np.array([0.03, 15.0], dtype=np.float32)\n",
    "\n",
    "# Take a step in the environment using the sample action\n",
    "next_state, reward, done, info = env.step(action)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nAction Taken:\", action)\n",
    "print(\"Next State:\", next_state)\n",
    "# env.render()\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Done:\", done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an RL agent on the environment from above\n",
    "\n",
    "env = GridEnv()\n",
    "lr = 3e-3\n",
    "total_timesteps = 1e6\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate = lr)\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "# model.save(\"\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "# model = PPO.load(\"ppo_cartpole\")\n",
    "\n",
    "# obs = vec_env.reset()\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, dones, info = vec_env.step(action)\n",
    "#     vec_env.render(\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, num_evaluations, env):\n",
    "    # idea: plot residual as a function of actions?\n",
    "    raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ictwi_alliander_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
