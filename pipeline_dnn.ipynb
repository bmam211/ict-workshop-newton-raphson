{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e9573c2e35c44e",
   "metadata": {},
   "source": [
    "# Power Flow Neural Network Training with Pandapower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e29ffe2e7920de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:30:36.793326Z",
     "start_time": "2025-01-21T14:30:26.828344Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter # for pytorch visualization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # normalize input features and target values\n",
    "from sklearn.model_selection import ParameterGrid # for hyperparameter tuning\n",
    "\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c544dc9ac3f11ff",
   "metadata": {},
   "source": [
    "### 1. Import Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f12038d1d4aaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:35:35.365251Z",
     "start_time": "2025-01-21T14:35:35.326547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./grid dataset/vector_data.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fb10ff26e6c08",
   "metadata": {},
   "source": [
    "### 2. Create Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b780979cebdbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(DeepNN, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c917333691c8b907",
   "metadata": {},
   "source": [
    "### 3. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed112667f7a0282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- BEST MODEL - Epoch 0 - Val Loss 1.011861 -------------\n",
      "Epoch 000, Loss: 1.020568, Val Loss: 1.011861\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# add dataset here\n",
    "data = torch.randn(1000, 84)\n",
    "labels = torch.randn(1000, 14)\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# dataloaders\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# model, loss, optimizer\n",
    "input_size = len(dataset[0][0])\n",
    "output_size = len(dataset[0][1])\n",
    "model = DeepNN(input_size=input_size, hidden_layers=[64,64], output_size=output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "writer = SummaryWriter()\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for X,Y in train_loader:\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X,Y in val_loader:\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './saved_models/best_model.pth')\n",
    "        print(f\"------------- BEST MODEL - Epoch {epoch} - Val Loss {val_loss:.6f} -------------\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:03}, Loss: {loss.item():.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462f6bba0c0d845",
   "metadata": {},
   "source": [
    "### 4. Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec720f92675663a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HeydarianArdakaniA\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandapower\\pf\\create_jacobian.py:28: RuntimeWarning: invalid value encountered in divide\n",
      "  dVm_x, dVa_x = dSbus_dV_numba_sparse(Ybus.data, Ybus.indptr, Ybus.indices, V, V / abs(V), Ibus)\n",
      "c:\\Users\\HeydarianArdakaniA\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandapower\\pypower\\newtonpf.py:337: MatrixRankWarning: Matrix is exactly singular\n",
      "  dx = -1 * spsolve(J, F, permc_spec=permc_spec, use_umfpack=use_umfpack)\n"
     ]
    },
    {
     "ename": "LoadflowNotConverged",
     "evalue": "Power Flow nr did not converge after 50 iterations!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLoadflowNotConverged\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m V_ang_pred \u001b[38;5;241m=\u001b[39m output[n_buses:]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Run power flow to ensure internal data is available\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pp.runpp(net, calculate_voltage_angles=True)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m pp\u001b[38;5;241m.\u001b[39mrunpp(net,\n\u001b[0;32m     26\u001b[0m          init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m          init_vm_pu\u001b[38;5;241m=\u001b[39mV_mag_pred,\n\u001b[0;32m     28\u001b[0m          init_va_degree\u001b[38;5;241m=\u001b[39mV_ang_pred,\n\u001b[0;32m     29\u001b[0m          max_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     30\u001b[0m          tolerance_mva\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Get reference values from the network\u001b[39;00m\n\u001b[0;32m     33\u001b[0m V_mag_ref \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mres_bus\u001b[38;5;241m.\u001b[39mvm_pu\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\HeydarianArdakaniA\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandapower\\run.py:250\u001b[0m, in \u001b[0;36mrunpp\u001b[1;34m(net, algorithm, calculate_voltage_angles, init, max_iteration, tolerance_mva, trafo_model, trafo_loading, enforce_q_lims, check_connectivity, voltage_depend_loads, consider_line_temperature, run_control, distributed_slack, tdpf, tdpf_delay_s, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m _check_bus_index_and_print_warning_if_high(net)\n\u001b[0;32m    249\u001b[0m _check_gen_index_and_print_warning_if_high(net)\n\u001b[1;32m--> 250\u001b[0m _powerflow(net, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HeydarianArdakaniA\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandapower\\powerflow.py:86\u001b[0m, in \u001b[0;36m_powerflow\u001b[1;34m(net, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m result \u001b[38;5;241m=\u001b[39m _run_pf_algorithm(ppci, net[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_options\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# read the results (=ppci with results) to net\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m _ppci_to_net(result, net)\n",
      "File \u001b[1;32mc:\\Users\\HeydarianArdakaniA\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandapower\\powerflow.py:190\u001b[0m, in \u001b[0;36m_ppci_to_net\u001b[1;34m(result, net)\u001b[0m\n\u001b[0;32m    188\u001b[0m     algorithm \u001b[38;5;241m=\u001b[39m net[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_options\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    189\u001b[0m     max_iteration \u001b[38;5;241m=\u001b[39m net[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_options\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LoadflowNotConverged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPower Flow \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m did not converge after \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m iterations!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(algorithm, max_iteration))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     net[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ppc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[1;31mLoadflowNotConverged\u001b[0m: Power Flow nr did not converge after 50 iterations!"
     ]
    }
   ],
   "source": [
    "net = pp.networks.example_simple()\n",
    "pp.runpp(net, max_iteration=1, tolerance_mva=np.inf)\n",
    "\n",
    "# Prepare input\n",
    "Ybus = net._ppc[\"internal\"][\"Ybus\"].toarray()\n",
    "S = net._ppc[\"internal\"][\"Sbus\"]\n",
    "input_tensor = torch.FloatTensor(np.concatenate([\n",
    "    S.real, \n",
    "    S.imag,\n",
    "    Ybus.real.flatten(), \n",
    "    Ybus.imag.flatten(),\n",
    "]))\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Split prediction into voltage magnitudes and angles\n",
    "n_buses = len(net.bus)\n",
    "V_mag_pred = output[:n_buses].numpy()\n",
    "V_ang_pred = output[n_buses:].numpy()\n",
    "\n",
    "# Run power flow to ensure internal data is available\n",
    "# pp.runpp(net, calculate_voltage_angles=True)\n",
    "pp.runpp(net,\n",
    "         init=\"auto\",\n",
    "         init_vm_pu=V_mag_pred,\n",
    "         init_va_degree=V_ang_pred,\n",
    "         max_iteration=50,\n",
    "         tolerance_mva=1e-5)\n",
    "\n",
    "# Get reference values from the network\n",
    "V_mag_ref = net.res_bus.vm_pu.values\n",
    "V_ang_ref = net.res_bus.va_degree.values\n",
    "\n",
    "print(\"Predicted voltage magnitudes:\", V_mag_pred)\n",
    "print(\"Predicted voltage angles:\", V_ang_pred)\n",
    "print(\"Reference voltage magnitudes:\", V_mag_ref)\n",
    "print(\"Reference voltage angles:\", V_ang_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750e487a27f2cbf",
   "metadata": {},
   "source": [
    "### 6. Additional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2045875b3bbdec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, val_loader, criterion):\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             batch_inputs = batch['input']\n",
    "#             batch_targets = batch['output']\n",
    "#             outputs = model(batch_inputs)\n",
    "#             loss = criterion(outputs, batch_targets)\n",
    "#             val_loss += loss.item()\n",
    "#     val_loss /= len(val_loader)\n",
    "#     return val_loss\n",
    "\n",
    "# def hyperparameter_tuning(base_network, param_grid):\n",
    "#     best_model = None\n",
    "#     best_loss = float('inf')\n",
    "#     dataset = PowerFlowDataset(base_network)\n",
    "#     train_size = int(0.8 * len(dataset))\n",
    "#     val_size = len(dataset) - train_size\n",
    "#     _, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#     for params in ParameterGrid(param_grid):\n",
    "#         print(f\"Training with parameters: {params}\")\n",
    "#         model = train_power_flow_model(base_network, num_epochs=params['num_epochs'], batch_size=params['batch_size'])\n",
    "#         val_loss = evaluate_model(model, val_loader, nn.MSELoss())\n",
    "#         if val_loss < best_loss:\n",
    "#             best_loss = val_loss\n",
    "#             best_model = model\n",
    "#     return best_model\n",
    "\n",
    "# base_network = pp.networks.example_simple()\n",
    "# param_grid = {\n",
    "#     'num_epochs': [50, 100],\n",
    "#     'batch_size': [16, 32],\n",
    "#     'hidden_size': [256, 512]\n",
    "# }\n",
    "# best_model = hyperparameter_tuning(base_network, param_grid)\n",
    "# # ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
