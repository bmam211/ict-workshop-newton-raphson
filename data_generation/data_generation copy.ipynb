{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 2-bus example\n",
    "\n",
    "class SimpleTwoBus:\n",
    "\n",
    "    def __init__(self, P, Q, G, B, V_init, theta_init):\n",
    "        '''This class creates a simple 2-bus network.'''\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.G = G\n",
    "        self.B = B\n",
    "        self.V_init = V_init\n",
    "        self.theta_init = theta_init\n",
    "        self.net = pp.create_empty_network()\n",
    "        self.create_two_bus_grid()\n",
    "\n",
    "\n",
    "\n",
    "    def create_two_bus_grid(self):\n",
    "        # Create an empty network\n",
    "        # net = pp.create_empty_network()\n",
    "    \n",
    "        # Create two buses with initialized voltage and angle\n",
    "        bus1 = pp.create_bus(self.net, vn_kv=20.0, name=\"Bus 1\")\n",
    "        bus2 = pp.create_bus(self.net, vn_kv=0.4, name=\"Bus 2\")\n",
    "    \n",
    "        # Initialize voltage and angle for buses\n",
    "        self.net.bus.loc[bus1, 'vm_pu'] = self.V_init[0]\n",
    "        self.net.bus.loc[bus1, 'va_degree'] = self.theta_init[0]\n",
    "        self.net.bus.loc[bus2, 'vm_pu'] = self.V_init[1]\n",
    "        self.net.bus.loc[bus2, 'va_degree'] = self.theta_init[1]\n",
    "    \n",
    "        # Create a transformer between the two buses\n",
    "        pp.create_transformer(self.net, bus1, bus2, std_type=\"0.25 MVA 20/0.4 kV\")\n",
    "    \n",
    "        # Create a load at bus 2 with specified P and Q\n",
    "        pp.create_load(self.net, bus2, p_mw=self.P, q_mvar=self.Q, name=\"Load\")\n",
    "    \n",
    "        # Create an external grid connection at bus 1 with specified G and B\n",
    "        pp.create_ext_grid(self.net, bus1, vm_pu=1.02, name=\"Grid Connection\", s_sc_max_mva=self.G, rx_max=self.B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network model\n",
    "class PowerFlowNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PowerFlowNN, self).__init__()\n",
    "        # self.fc1 = nn.Linear(8, 10)  # Adjust input size to match the concatenated input size\n",
    "        # self.fc2 = nn.Linear(10, 10)\n",
    "        # self.fc3 = nn.Linear(10, 8)  # Output size should match the number of buses * 2 (voltage magnitudes and angles)\n",
    "\n",
    "        self.fc1 = nn.Linear(2, 1000)  # Adjust input size to match the concatenated input size\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 14)  # Output size should match the number of buses\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class that generates and saves a dataset using runpp newton-raphson power flow\n",
    "\n",
    "class PowerFlowDataset(Dataset):\n",
    "    def __init__(self, base_network, num_samples=1000, max_iteration=50, tolerance_mva=1e-8):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with a base network and number of samples.\n",
    "       \n",
    "        Parameters:\n",
    "        base_network (pandapowerNet): The base pandapower network.\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        \"\"\"\n",
    "        self.base_net = base_network.deepcopy()  # Ensure base network is not modified\n",
    "        self.num_samples = num_samples\n",
    "        self.samples = []\n",
    "        self.scaler_input = StandardScaler()\n",
    "        self.scaler_output = StandardScaler()\n",
    "        self.max_iteration = max_iteration\n",
    "        self.tolerance_mva = tolerance_mva\n",
    " \n",
    "        self.generate_samples()\n",
    "        self.normalize_samples()\n",
    " \n",
    "    def generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generate samples by first running normal power flow and then perturbing it to create ill-conditioning.\n",
    "        \"\"\"\n",
    "        # Run a normal power flow first\n",
    "        net = self.base_net.deepcopy()\n",
    "        try:\n",
    "            pp.runpp(net, max_iteration=100)  # Solve with standard conditions\n",
    "            print(\"Base case solved successfully.\")\n",
    "        except pp.powerflow.LoadflowNotConverged:\n",
    "            print(\"Base case did not converge. Check the network setup.\")\n",
    "            return\n",
    "       \n",
    "        # Extract the normal solution\n",
    "        v_nominal = net.res_bus.vm_pu.values  # Nominal voltage magnitudes\n",
    "        theta_nominal = net.res_bus.va_degree.values  # Nominal voltage angles\n",
    "       \n",
    "        for _ in range(self.num_samples):\n",
    "            net_ill = self.base_net.deepcopy()  # Keep the network unchanged\n",
    " \n",
    "            # --- Create an ill-conditioned case ---\n",
    "            v_ill = v_nominal + np.random.uniform(-0.15, 0.15, len(v_nominal))  # Small perturbation\n",
    "            theta_ill = theta_nominal + np.random.uniform(-30, 30, len(theta_nominal))  # Large phase shift\n",
    "            # p_ill = net_ill.res_bus.p_mw.values + np.random.uniform(-200, 200, len(v_nominal))  # Large power mismatch\n",
    " \n",
    "            try:\n",
    "                # Re-run power flow with ill-conditioned initialization\n",
    "                pp.runpp(net_ill,\n",
    "                         init=\"auto\",\n",
    "                         init_vm_pu=v_ill,\n",
    "                         init_va_degree=theta_ill,\n",
    "                         max_iteration=self.max_iteration,\n",
    "                         tolerance_mva=self.tolerance_mva)\n",
    "               \n",
    "                iterations = net_ill._ppc[\"iterations\"]\n",
    "                print(f\"Sample {_}: Converged in {iterations} iterations\")\n",
    " \n",
    "                # Extract ill-conditioned solution\n",
    "                Ybus = net_ill._ppc[\"internal\"][\"Ybus\"].toarray()\n",
    "                S = net_ill._ppc[\"internal\"][\"Sbus\"]\n",
    "                it = net._ppc[\"iterations\"]\n",
    "                et = net._ppc[\"et\"]\n",
    "                V_mag = net_ill.res_bus.vm_pu.values\n",
    "                V_ang = net_ill.res_bus.va_degree.values\n",
    "               \n",
    "                # self.samples.append({\n",
    "                #     \"input\": np.concatenate([Ybus.real.flatten(), Ybus.imag.flatten(), S.real, S.imag]),\n",
    "                #     \"output\": np.concatenate([V_mag, V_ang])\n",
    "                # })\n",
    " \n",
    "                self.samples.append({\n",
    "                                \"input\": np.concatenate([Ybus.real.flatten(),\n",
    "                                                        Ybus.imag.flatten(),\n",
    "                                                        S.real,\n",
    "                                                        S.imag]),\n",
    "                                \"output\": np.concatenate([V_mag, V_ang]),\n",
    "                                \"iteration\": it,\n",
    "                                \"residual error\": et,\n",
    "                            })\n",
    "\n",
    "            except pp.powerflow.LoadflowNotConverged:\n",
    "                print(f\"Sample {_}: Ill-conditioned case did not converge!\")\n",
    "        \n",
    "        with open( \"data.pkl\", \"wb\") as f:\n",
    "            pickle.dump(self.samples, f)\n",
    "\n",
    "        \n",
    " \n",
    "    def normalize_samples(self):\n",
    "        \"\"\"\n",
    "        Normalize the input features and target values.\n",
    "        \"\"\"\n",
    "        if not self.samples:\n",
    "            raise ValueError(\"No valid samples generated!\")\n",
    " \n",
    "        inputs = np.array([sample[\"input\"] for sample in self.samples])\n",
    "        outputs = np.array([sample[\"output\"] for sample in self.samples])\n",
    " \n",
    "        self.scaler_input.fit(inputs)\n",
    "        self.scaler_output.fit(outputs)\n",
    " \n",
    "        for sample in self.samples:\n",
    "            sample[\"input\"] = self.scaler_input.transform([sample[\"input\"]])[0]\n",
    "            sample[\"output\"] = self.scaler_output.transform([sample[\"output\"]])[0]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return {\n",
    "            'input': torch.FloatTensor(sample['input']),\n",
    "            'output': torch.FloatTensor(sample['output'])\n",
    "        }\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base case solved successfully.\n",
      "Sample 0: Converged in 4 iterations\n",
      "Sample 1: Converged in 4 iterations\n",
      "Sample 2: Converged in 4 iterations\n",
      "Sample 3: Converged in 4 iterations\n",
      "Sample 4: Converged in 4 iterations\n",
      "Sample 5: Converged in 4 iterations\n",
      "Sample 6: Converged in 5 iterations\n",
      "Sample 7: Converged in 4 iterations\n",
      "Sample 8: Converged in 4 iterations\n",
      "Sample 9: Converged in 4 iterations\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset based on given initial values\n",
    "\n",
    "P = 0.1  # Active power in MW\n",
    "Q = 0.05  # Reactive power in MVar\n",
    "G = 100  # Short-circuit power in MVA\n",
    "B = 0.1  # Short-circuit impedance\n",
    "V_init = [1.02, 1.0]  # Initial voltages in pu\n",
    "theta_init = [0, 0]  # Initial angles in degrees\n",
    "\n",
    "# create network object\n",
    "Net = SimpleTwoBus(P,Q,G,B,V_init,theta_init)\n",
    "net = Net.net\n",
    "\n",
    "# generate data\n",
    "PF_data = PowerFlowDataset(net, num_samples=10, max_iteration=50, tolerance_mva=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below this was all prior work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform power flow calculation using Newton-Raphson method\n",
    "# def power_flow_calculation(net):\n",
    "\n",
    "#     pp.runpp(net, algorithm='nr', tolerance_mva=1e-8, max_iteration = 1000)\n",
    "#     iterations = net._ppc[\"iterations\"]\n",
    "\n",
    "    \n",
    "#     return np.concatenate((net.res_bus.vm_pu.values, net.res_bus.va_degree.values)), iterations\n",
    "\n",
    "# # Generate training data\n",
    "# def generate_training_data(net, num_samples=1000):\n",
    "#     inputs = []\n",
    "#     targets = []\n",
    "#     iterations = []\n",
    "#     for _ in range(num_samples):\n",
    "#         # Randomly perturb the load values\n",
    "#         net.load.p_mw += (np.random.rand(len(net.load)) - 0.5) * 0.1\n",
    "#         net.load.q_mvar += (np.random.rand(len(net.load)) - 0.5) * 0.1\n",
    "        \n",
    "#         # Perform power flow calculation\n",
    "#         target, k = power_flow_calculation(net)\n",
    "        \n",
    "#         # Store the input and target values\n",
    "#         input_values = np.concatenate((net.load.p_mw.values, net.load.q_mvar.values))\n",
    "#         inputs.append(input_values)\n",
    "#         targets.append(target)\n",
    "#         iterations.append(k)\n",
    "    \n",
    "#     inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "#     targets = torch.tensor(targets, dtype=torch.float32)\n",
    "    \n",
    "#     return inputs, targets, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_model(model, num_epochs, optimizer, criterion, targets, inputs):\n",
    "\n",
    "    # Train the neural network model\n",
    "    # num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "# Compare the predicted values of the neural network model with the real network\n",
    "def compare_predictions_with_real_network(net, model):\n",
    "    # Perform power flow calculation on the real network\n",
    "    real_values = power_flow_calculation(net)\n",
    "    \n",
    "    # Prepare input data for the neural network model\n",
    "    input_values = np.concatenate((net.load.p_mw.values, net.load.q_mvar.values))\n",
    "    input_tensor = torch.tensor(input_values, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Get predictions from the neural network model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_values = model(input_tensor).squeeze().numpy()\n",
    "    \n",
    "    # Split predicted values into voltage magnitudes and angles\n",
    "    predicted_vm_pu = predicted_values[:len(net.res_bus)]\n",
    "    predicted_va_degree = predicted_values[len(net.res_bus):]\n",
    "\n",
    "    difference_va_degree = predicted_va_degree - real_values[7:]\n",
    "    difference_vm_pu = predicted_vm_pu - real_values[0:7]\n",
    "    \n",
    "    # Print predicted voltage angles for comparison\n",
    "    print(\"Predicted Voltage Angles: \", predicted_va_degree)\n",
    "\n",
    "    print(\"Reference voltage angles:\", real_values[7:])\n",
    "\n",
    "    print(\"Predicted Voltage Magnitudes: \", predicted_vm_pu)\n",
    "\n",
    "    print(\"Reference voltage magnitudes: \", real_values[0:7])\n",
    "\n",
    "    print(\"Diffefrences:\")\n",
    "\n",
    "    print(f\"{difference_va_degree=}\")\n",
    "    print(f\"{difference_vm_pu=}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape:  torch.Size([100, 2])\n",
      "Targets shape:  torch.Size([100, 4])\n",
      "iterations=[3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple power network using pandapower\n",
    "# net = pp.networks.example_simple()\n",
    "# Example usage\n",
    "P = 0.1  # Active power in MW\n",
    "Q = 0.05  # Reactive power in MVar\n",
    "G = 100  # Short-circuit power in MVA\n",
    "B = 0.1  # Short-circuit impedance\n",
    "V_init = [1.02, 1.0]  # Initial voltages in pu\n",
    "theta_init = [0, 0]  # Initial angles in degrees\n",
    "Net = SimpleTwoBus(P,Q,G,B,V_init,theta_init)\n",
    "net = Net.net\n",
    "\n",
    "# Initialize the neural network model\n",
    "model = PowerFlowNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Generate training data\n",
    "inputs, targets, iterations = generate_training_data(net, num_samples = 100)\n",
    "# Print shapes of inputs and targets to verify\n",
    "print(\"Inputs shape: \", inputs.shape)\n",
    "print(\"Targets shape: \", targets.shape)\n",
    "print(f\"{iterations=}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lindsayspoor/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([100, 4])) that is different to the input size (torch.Size([100, 14])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (14) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_network_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m, in \u001b[0;36mtrain_network_model\u001b[0;34m(model, num_epochs, optimizer, criterion, targets, inputs)\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m----> 8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/nn/functional.py:3791\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[1;32m   3793\u001b[0m     expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3794\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/PhD/Projects/ictwi_alliander/.venv/lib/python3.9/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (14) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "train_network_model(model, num_epochs, optimizer, criterion, targets, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Voltage Angles:  [ 47.25534   47.39404   47.354042 -93.285995 -93.3258   -93.27554\n",
      " -93.15478 ]\n",
      "Reference voltage angles: [ 50.          50.0346054   50.0346054  -98.110326   -98.110326\n",
      " -98.04583138 -97.94416185]\n",
      "Predicted Voltage Magnitudes:  [0.961529   0.95510197 0.9513805  0.9575139  0.9274514  0.9759572\n",
      " 0.95710087]\n",
      "Reference voltage magnitudes:  [1.02       1.02084103 1.02084103 1.02451121 1.02451121 1.03\n",
      " 1.02332043]\n",
      "Diffefrences:\n",
      "difference_va_degree=array([-2.74465942, -2.64056624, -2.68056334,  4.82433051,  4.78452796,\n",
      "        4.77028816,  4.78938432])\n",
      "difference_vm_pu=array([-0.05847098, -0.06573906, -0.06946054, -0.06699728, -0.09705984,\n",
      "       -0.05404279, -0.06621956])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare predictions with real network values\n",
    "compare_predictions_with_real_network(net, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.runpp(net, algorithm='nr')\n",
    "\n",
    "# Prepare input\n",
    "Ybus = net._ppc[\"internal\"][\"Ybus\"].toarray()\n",
    "S = net._ppc[\"internal\"][\"Sbus\"]\n",
    "input_tensor = torch.FloatTensor(np.concatenate([\n",
    "    Ybus.real.flatten(), \n",
    "    Ybus.imag.flatten(),\n",
    "    S.real, \n",
    "    S.imag\n",
    "]))\n",
    "\n",
    "V_mag_ref = net.res_bus.vm_pu.values \n",
    "V_ang_ref = net.res_bus.va_degree.values\n",
    "\n",
    "print(\"Reference voltage magnitudes:\", V_mag_ref)\n",
    "print(\"Reference voltage angles:\", V_ang_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "amir's stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "class PowerFlowDataset(Dataset):\n",
    "    def __init__(self, base_network, num_samples=1000):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with a base network and number of samples.\n",
    "       \n",
    "        Parameters:\n",
    "        base_network (pandapowerNet): The base pandapower network.\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        \"\"\"\n",
    "        self.base_net = base_network.deepcopy()  # Ensure base network is not modified\n",
    "        self.num_samples = num_samples\n",
    "        self.samples = []\n",
    "        self.scaler_input = StandardScaler()\n",
    "        self.scaler_output = StandardScaler()\n",
    " \n",
    "        self.generate_samples()\n",
    "        self.normalize_samples()\n",
    " \n",
    "    def generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generate samples by first running normal power flow and then perturbing it to create ill-conditioning.\n",
    "        \"\"\"\n",
    "        # Run a normal power flow first\n",
    "        net = self.base_net.deepcopy()\n",
    "        try:\n",
    "            pp.runpp(net, max_iteration=100)  # Solve with standard conditions\n",
    "            print(\"Base case solved successfully.\")\n",
    "        except pp.powerflow.LoadflowNotConverged:\n",
    "            print(\"Base case did not converge. Check the network setup.\")\n",
    "            return\n",
    "       \n",
    "        # Extract the normal solution\n",
    "        v_nominal = net.res_bus.vm_pu.values  # Nominal voltage magnitudes\n",
    "        theta_nominal = net.res_bus.va_degree.values  # Nominal voltage angles\n",
    "       \n",
    "        for _ in range(self.num_samples):\n",
    "            net_ill = self.base_net.deepcopy()  # Keep the network unchanged\n",
    " \n",
    "            # --- Create an ill-conditioned case ---\n",
    "            v_ill = v_nominal + np.random.uniform(-0.15, 0.15, len(v_nominal))  # Small perturbation\n",
    "            theta_ill = theta_nominal + np.random.uniform(-30, 30, len(theta_nominal))  # Large phase shift\n",
    "            # p_ill = net_ill.res_bus.p_mw.values + np.random.uniform(-200, 200, len(v_nominal))  # Large power mismatch\n",
    " \n",
    "            try:\n",
    "                # Re-run power flow with ill-conditioned initialization\n",
    "                pp.runpp(net_ill,\n",
    "                         init=\"auto\",\n",
    "                         init_vm_pu=v_ill,\n",
    "                         init_va_degree=theta_ill,\n",
    "                         max_iteration=50)\n",
    "               \n",
    "                iterations = net_ill._ppc[\"iterations\"]\n",
    "                print(f\"Sample {_}: Converged in {iterations} iterations\")\n",
    " \n",
    "                # Extract ill-conditioned solution\n",
    "                Ybus = net_ill._ppc[\"internal\"][\"Ybus\"].toarray()\n",
    "                S = net_ill._ppc[\"internal\"][\"Sbus\"]\n",
    "                V_mag = net_ill.res_bus.vm_pu.values\n",
    "                V_ang = net_ill.res_bus.va_degree.values\n",
    "               \n",
    "                self.samples.append({\n",
    "                    \"input\": np.concatenate([Ybus.real.flatten(), Ybus.imag.flatten(), S.real, S.imag]),\n",
    "                    \"output\": np.concatenate([V_mag, V_ang])\n",
    "                })\n",
    " \n",
    "            except pp.powerflow.LoadflowNotConverged:\n",
    "                print(f\"Sample {_}: Ill-conditioned case did not converge!\")\n",
    " \n",
    "    def normalize_samples(self):\n",
    "        \"\"\"\n",
    "        Normalize the input features and target values.\n",
    "        \"\"\"\n",
    "        if not self.samples:\n",
    "            raise ValueError(\"No valid samples generated!\")\n",
    " \n",
    "        inputs = np.array([sample[\"input\"] for sample in self.samples])\n",
    "        outputs = np.array([sample[\"output\"] for sample in self.samples])\n",
    " \n",
    "        self.scaler_input.fit(inputs)\n",
    "        self.scaler_output.fit(outputs)\n",
    " \n",
    "        for sample in self.samples:\n",
    "            sample[\"input\"] = self.scaler_input.transform([sample[\"input\"]])[0]\n",
    "            sample[\"output\"] = self.scaler_output.transform([sample[\"output\"]])[0]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        return {\n",
    "            'input': torch.FloatTensor(sample['input']),\n",
    "            'output': torch.FloatTensor(sample['output'])\n",
    "        }\n",
    " \n",
    " \n",
    " \n",
    "net = pp.networks.example_simple()\n",
    "PF_data = PowerFlowDataset(net, num_samples=10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
